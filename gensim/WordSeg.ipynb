{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "中文文档预处理及分词，可以输出为gensim能训练的文件格式，允许载入自定义词典，停用词词典，预处理包括繁简转换，去掉非中文字符，去掉停用词\n",
    "\n",
    "jieba官方文档\n",
    "https://github.com/fxsjy/jieba\n",
    "\n",
    "简繁转换用opencc实现\n",
    "参考http://blog.csdn.net/tab_space/article/details/50823073\n",
    "`pip install opencc-python`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onclick=\"$('.output_stderr').toggle();\">Toggle Code</button>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<button onclick=\"$('.output_stderr').toggle();\">Toggle Code</button>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jieba import posseg\n",
    "import jieba\n",
    "import re\n",
    "import sys\n",
    "\n",
    "#明确定义使用utf8解码，默认是ANSCII\n",
    "reload(sys)  \n",
    "sys.setdefaultencoding('utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#一直有报错\n",
    "#import opencc\n",
    "#cc = opencc.OpenCC('t2s', data_path='/home/david/code/python/opencc/opencc-python-0.1/opencc/data')\n",
    "#print cc.convert(u'Open Chinese Convert（OpenCC）「開放中文轉換」，是一個致力於中文簡繁轉換的項目，提供高質量詞庫和函數庫(libopencc)。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "使用结巴进行分词，可以加载自定义词典和停用词词典，可以过滤非中文字符\n",
    "segMode :\n",
    "e -- 精确模式，试图将句子最精确地切开，适合文本分析，也是默认的模式\n",
    "a -- 全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义\n",
    "s -- 搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词\n",
    "userDictPath：用户自定义词典\n",
    "stopWordPath：停用词词典\n",
    "isFilterNoChinese：是否过滤非中文字符，默认过滤\n",
    "'''\n",
    "class WordSeg(object):\n",
    "    def __init__(self, segMode, userDictPath = None, stopWordPath = None, isFilterNoChinese = True):\n",
    "        self._segMode = segMode\n",
    "        self._userDictPath = userDictPath\n",
    "        self._stopWordPath = stopWordPath\n",
    "        self._isFilterNoChinese = isFilterNoChinese\n",
    "        \n",
    "    def filterNoChinese(self, segStr):\n",
    "        pattern = re.compile(ur'[^\\u4e00-\\u9fa5]')\n",
    "        #去掉多余的空格 \n",
    "        return re.sub(r\"\\s{2,}\", \"\", \" \".join(pattern.split(segStr)).strip())\n",
    "    \n",
    "    def generateStopWords(self):\n",
    "        stopWords = {}\n",
    "        if not self._stopWordPath == None:\n",
    "            fstop = open(self._stopWordPath, 'r')\n",
    "            for word in fstop:\n",
    "                #解码为unicode进行处理\n",
    "                stopWords[word.strip().decode('utf-8', 'ignore')] = word.strip().decode('utf-8', 'ignore')\n",
    "        return stopWords\n",
    "        \n",
    "    def seg(self, segStr):\n",
    "        segStr = segStr.strip().decode('utf8', 'ignore')\n",
    "        if not self._userDictPath == None:\n",
    "            jieba.load_userdict(self._userDictPath)\n",
    "            \n",
    "        if self._isFilterNoChinese:\n",
    "            segStr = self.filterNoChinese(segStr)\n",
    "        \n",
    "        #多线程分词\n",
    "        jieba.enable_parallel(5)\n",
    "        wordGenList = []\n",
    "        if self._segMode == 'a':\n",
    "            wordGenList = [word for word in jieba.cut(segStr, cut_all=True) if word not in self.generateStopWords()]\n",
    "        elif self._segMode == 's':\n",
    "            wordGenList = [word for word in jieba.cut_for_search(segStr) if word not in self.generateStopWords()]\n",
    "        else:\n",
    "            wordGenList = [word for word in jieba.cut(segStr, cut_all=False) if word not in self.generateStopWords()]\n",
    "        \n",
    "        return wordGenList\n",
    "    \n",
    "    def posSeg(self, segStr):\n",
    "        segStr = segStr.strip().decode('utf8', 'ignore')\n",
    "        if not self._userDictPath == None:\n",
    "            jieba.load_userdict(self._userDictPath)\n",
    "            \n",
    "        if self._isFilterNoChinese:\n",
    "            segStr = self.filterNoChinese(segStr)\n",
    "        wordPosGenList = posseg.cut(segStr, HMM=True)\n",
    "        return wordPosGenList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
